{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3ZF3oYIJ3KW"
   },
   "source": [
    "Due Date: December 7th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzptQhdh0pUr"
   },
   "source": [
    "# Vaccine Development with Dynamic Programming\n",
    "\n",
    "You are the CEO of a biotech company which is considering the development of a new vaccine. Starting at phase 0 (state 0), the drug develpment can stay in the same state or advance to \"phase 1  with promising results\" (state 1) or advance to \"phase 1 with disappointing results\" (state 2), or fail completely (state 4). At phase 1, the drug can stay in the same state, fail or become a success (state 3), in which case you will sell its patent to a big pharma company for $\\$10$ million.\n",
    "These state transitions happen from month to month, and at each state, you have the option to make an additional investment of \\$100,000, which increases the chances of success.\n",
    "\n",
    "After careful study, your analysts develop the program below to simulate different scenarios using statistical data from similar projects. \n",
    "\n",
    "Use a discount factor of 0.996.\n",
    "\n",
    "- 1) Write a policy iteration algorithm to compute the value of this project. Please print the full V vector.\n",
    "\n",
    "- 2 )Write a value iteration algorithm to compute the value of this project. Please print the full V vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:11:42.182312Z",
     "start_time": "2022-12-08T02:11:42.176024Z"
    },
    "id": "dnAvrShs6ecs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MDP():\n",
    "    def __init__(self):\n",
    "        self.A = [0, 1]\n",
    "        self.S = [0, 1, 2, 3, 4]\n",
    "\n",
    "        P0 = np.array([[0.5, .15, .15, 0, .20],\n",
    "                       [0, .5, .0, .25, .25],\n",
    "                       [0, 0, .15, .05, .8],\n",
    "                       [0, 0, 0, 0, 1],\n",
    "                       [0, 0, 0, 0, 1]])\n",
    "\n",
    "        R0 = np.array([0, 0, 0, 10, 0])\n",
    "\n",
    "        P1 = np.array([[0.5, .25, .15, 0, .10],\n",
    "                       [0, .5, .0, .35, .15],\n",
    "                       [0, 0, .20, .05, .75],\n",
    "                       [0, 0, 0, 0, 1],\n",
    "                       [0, 0, 0, 0, 1]])\n",
    "\n",
    "        R1 = np.array([-0.1, -0.1, -0.1, 10, 0])\n",
    "\n",
    "        self.P = [P0, P1]\n",
    "        self.R = [R0, R1]\n",
    "\n",
    "    def step(self, s, a):\n",
    "        s_prime = np.random.choice(len(self.S), p=self.P[a][s])\n",
    "        R = self.R[a][s]\n",
    "        if s_prime == 4:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        return s_prime, R, done\n",
    "\n",
    "    def simulate(self, s, a, π):\n",
    "        done = False\n",
    "        t = 0\n",
    "        history = []\n",
    "        while not done:\n",
    "            if t > 0:\n",
    "                a = π[s]\n",
    "            s_prime, R, done = self.step(s, a)\n",
    "            history.append((s, a, R))\n",
    "            s = s_prime\n",
    "            t += 1\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgAiJxSnZtkH"
   },
   "source": [
    "You can access the transition probability matrices and the reward vector as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:11:43.082947Z",
     "start_time": "2022-12-08T02:11:43.079322Z"
    },
    "id": "5-rfjh_37kmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "-0.1\n"
     ]
    }
   ],
   "source": [
    "mdp = MDP()\n",
    "P = mdp.P\n",
    "R = mdp.R\n",
    "\n",
    "\n",
    "s = 2  # current state\n",
    "s_prime = 4  # next state\n",
    "a = 1  # chosen action\n",
    "\n",
    "# Probability of transition from state s (2) to s_prime (4) if action == a (1):\n",
    "print(P[a][s, s_prime])\n",
    "\n",
    "# Reward at state s if action = a\n",
    "print(R[a][s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWfK-47V8I08"
   },
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:11:44.054343Z",
     "start_time": "2022-12-08T02:11:44.049129Z"
    }
   },
   "outputs": [],
   "source": [
    "π = [0, 0, 0,0,0]\n",
    "γ = 0.996\n",
    "\n",
    "def construct_Rπ(R, π, S):\n",
    "    Rπ = np.zeros(len(S))\n",
    "    for s in S:\n",
    "        Rπ[s] = R[π[s]][s]\n",
    "    return Rπ\n",
    "\n",
    "\n",
    "def construct_Pπ(P, π, S):\n",
    "    Pπ = np.zeros((len(S), len(S)))\n",
    "    for s in S:\n",
    "        for s_prime in S:\n",
    "            Pπ[s, s_prime] = P[π[s]][s, s_prime]\n",
    "    return Pπ\n",
    "\n",
    "def policy_evaluation(π, Vπ):\n",
    "    Rπ = construct_Rπ(mdp.R, π, mdp.S)\n",
    "    Pπ = construct_Pπ(mdp.P, π, mdp.S)\n",
    "    for iteration in range(1): #把這邊次數減少 \n",
    "        Vπ = Rπ + γ * Pπ @ Vπ\n",
    "    return Vπ\n",
    "\n",
    "\n",
    "def policy_improvement(Vπ):\n",
    "    # Compute Qπ using Vπ\n",
    "    Qπ = np.zeros((5, 2))\n",
    "    π_prime = np.zeros(5, dtype=np.int32)\n",
    "    for s in mdp.S:\n",
    "        for a in mdp.A:\n",
    "            Qπ[s, a] = R[a][s] + γ * P[a][s] @ Vπ\n",
    "\n",
    "    # Greedy updates\n",
    "    for s in mdp.S:\n",
    "        π_prime[s] = np.argmax(Qπ[s, :])\n",
    "    return π_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:11:44.537041Z",
     "start_time": "2022-12-08T02:11:44.525538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.32067538  6.74501992  0.58546908 10.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "Vπ = np.zeros(5)\n",
    "for iteration in range(100): #然後這邊次數增大\n",
    "    Vπ = policy_evaluation(π, Vπ)\n",
    "    π = policy_improvement(Vπ)\n",
    "print(Vπ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T02:11:45.440852Z",
     "start_time": "2022-12-08T02:11:45.433147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.32067538  6.74501992  0.58546908 10.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "v0 = np.zeros(5)\n",
    "γ = 0.996\n",
    "\n",
    "def update(v0):\n",
    "    v1 = np.zeros_like(v0)\n",
    "    for s in mdp.S:\n",
    "        v1[s] = np.max([R[a][s] + γ * P[a][s] @ v0 for a in mdp.A])\n",
    "    return v1\n",
    "\n",
    "\n",
    "for _ in range(2000):\n",
    "    v1 = update(v0)\n",
    "    error = np.abs(v0 - v1).max()\n",
    "    if error < 1e-10:\n",
    "        break\n",
    "    v0 = v1\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
